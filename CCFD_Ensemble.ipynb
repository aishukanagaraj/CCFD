{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyspark.ml.classification",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a9ee5ec73867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultilayerPerceptronClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGBTClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named pyspark.ml.classification"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import math\n",
    "\n",
    "algos=[\"RF\",\"ANN\",\"DT\",\"GBT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsePoint(line):\n",
    "    data=line.split(',')\n",
    "    values = [float(data[x]) for x in range(0,len(data)-1)]\n",
    "    #Tr\n",
    "    #values.append(values[5]-values[4])\n",
    "    #Tr\n",
    "    #values.append(values[7]-values[4])\n",
    "    #Tr\n",
    "    #values.append(values[16]-values[4])\n",
    "    \n",
    "    values.append(0 if (data[len(data)-1] == 'N') else 1)\n",
    "    return (values[len(values)-1],Vectors.dense(values[0:len(values)-1]))\n",
    "    \n",
    "\n",
    "def confCalc(a):\n",
    "    ideal,pred=a.label,a.prediction\n",
    "    tp=fp=tn=fn=0.0\n",
    "    if(ideal == 1 and pred == 1):\n",
    "        tp=1.0\n",
    "    if(ideal == 1 and pred == 0):\n",
    "        fn=1.0\n",
    "    if(ideal == 0 and pred == 0):\n",
    "        tn=1.0\n",
    "    if(ideal == 0 and pred == 1):\n",
    "        fp=1.0\n",
    "    \n",
    "    return(ideal,pred,tp,fp,tn,fn)\n",
    "\n",
    "def paramCalc(cf):\n",
    "    cf=sqlContext.createDataFrame(cf,['ideal','predicted','tp','fp','tn','fn'])\n",
    "    add=cf.agg(F.sum(cf.tp).alias('tp'),F.sum(cf.fp).alias('fp'),F.sum(cf.tn).alias('tn'),\\\n",
    "           F.sum(cf.fn).alias('fn'),\\\n",
    "           (F.sum(cf.fp)/(F.sum(cf.fp)+F.sum(cf.tn))).alias('fpr'),\\\n",
    "           (F.sum(cf.tp)/(F.sum(cf.tp)+F.sum(cf.fn))).alias('tpr'),\\\n",
    "           (F.sum(cf.tn)/(F.sum(cf.fp)+F.sum(cf.tn))).alias('tnr'),\\\n",
    "           (F.sum(cf.fn)/(F.sum(cf.tp)+F.sum(cf.fn))).alias('fnr'),\\\n",
    "           (F.sum(cf.tp)/(F.sum(cf.tp)+F.sum(cf.fn))).alias('recall'),\\\n",
    "           (F.sum(cf.tp)/(F.sum(cf.tp)+F.sum(cf.fp))).alias('precision'),\\\n",
    "           ((F.sum(cf.tp)+F.sum(cf.tn))/(F.sum(cf.tp)+F.sum(cf.fn)+F.sum(cf.tn)+F.sum(cf.fp))).alias('accuracy'),\\\n",
    "           (2*F.sum(cf.tp)/(2*F.sum(cf.tp)+F.sum(cf.fp)+F.sum(cf.fn))).alias('Fmeasure'),\\\n",
    "           (1-((F.sum(cf.tp)+F.sum(cf.tn))/(F.sum(cf.tp)+F.sum(cf.fn)+F.sum(cf.tn)+F.sum(cf.fp)))).alias('error'),\\\n",
    "          )\n",
    "    return add\n",
    "\n",
    "def nbExec(test):\n",
    "    predictions = nbModel.transform(test)\n",
    "    nbResult=predictions.select(\"label\",\"prediction\")\n",
    "    return nbResult\n",
    "\n",
    "def lrExec(test):\n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "    lrModel = lr.fit(test)\n",
    "    trainingSummary = lrModel.summary\n",
    "    lrResult=trainingSummary.predictions.select(\"label\",\"prediction\")\n",
    "    return lrResult\n",
    "\n",
    "def dtExec(test):\n",
    "    predictions = dtModel.transform(test)\n",
    "    dtResult=predictions.select(\"label\",\"prediction\")\n",
    "    return dtResult\n",
    "    \n",
    "def rfExec(test):\n",
    "    predictions = rfModel.transform(test)\n",
    "    rfResult=predictions.select(\"label\", \"prediction\")\n",
    "    return rfResult\n",
    "    \n",
    "def gbtExec(test):\n",
    "    predictions = gbtModel.transform(test)\n",
    "    gbtResult=predictions.select(\"label\",\"prediction\")\n",
    "    return gbtResult\n",
    "    \n",
    "def annExec(test):\n",
    "    result = annModel.transform(test)\n",
    "    annResult = result.select( \"label\",\"prediction\")\n",
    "    return annResult\n",
    "\n",
    "def run(technique):\n",
    "    if (technique=='LR'):\n",
    "        result=lrExec(test)\n",
    "    elif (technique=='NB'):\n",
    "        result=nbExec(test)\n",
    "    elif (technique=='DT'):\n",
    "        result=dtExec(test)\n",
    "    elif (technique=='RF'):\n",
    "        result=rfExec(test)\n",
    "    elif (technique=='GBT'):\n",
    "        result=gbtExec(test)\n",
    "    elif (technique=='ANN'):\n",
    "        result=annExec(test)\n",
    "        \n",
    "    return result,testData.select('id').rdd.collect()\n",
    "        \n",
    "def profitCalc(predictions):\n",
    "    \n",
    "    metricDF=sqlContext.createDataFrame([predictions],[\"Technique\",\"tp\",\"fp\",\"tn\",\"fn\",\"fpr\",\"tpr\",\"tnr\",\"fnr\",\"recall\",\"precision\",\"accuracy\",\"fmeasure\",\"error\"]) \n",
    "    \n",
    "    tp=metricDF.first()['tp']\n",
    "    fp=metricDF.first()['fp']\n",
    "    tn=metricDF.first()['tn']\n",
    "    fn=metricDF.first()['fn']\n",
    "    \n",
    "    gw=1\n",
    "    amount=100\n",
    "    \n",
    "    profit=(fp*gw)+(fn*amount)+(fn*gw/2.0)\n",
    "    \n",
    "    return (metricDF.select('Technique').rdd.collect()[0]['Technique'],profit)\n",
    "    \n",
    "def profitCalc1(predictions):\n",
    "    gamma=0.3\n",
    "    CLV=200\n",
    "    co=10\n",
    "    ca=1\n",
    "    \n",
    "    metricDF=sqlContext.createDataFrame([predictions],[\"Technique\",\"tp\",\"fp\",\"tn\",\"fn\",\"fpr\",\"tpr\",\"tnr\",\"fnr\",\"recall\",\"precision\",\"accuracy\",\"fmeasure\",\"error\"]) \n",
    "    \n",
    "    profit=metricDF.first()['tp']*(gamma*(CLV+co+ca)+((1-gamma)*ca))+(metricDF.first()['fp']*(-co-ca))\n",
    "    \n",
    "    return (metricDF.select('Technique').rdd.collect()[0]['Technique'],profit)\n",
    "\n",
    "def getModel(technique):\n",
    "    if (technique=='LR'):\n",
    "        result=lrModel.transform(test)\n",
    "    elif (technique=='NB'):\n",
    "        result=nbModel.transform(test)\n",
    "    elif (technique=='DT'):\n",
    "        result=dtModel.transform(test)\n",
    "    elif (technique=='RF'):\n",
    "        result=rfModel.transform(test)\n",
    "    elif (technique=='GBT'):\n",
    "        result=gbtModel.transform(test)\n",
    "    elif (technique=='ANN'):\n",
    "        result=annModel.transform(test)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LR():\n",
    "    global lrModel\n",
    "    \n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "    # Fit the model\n",
    "    lrModel = lr.fit(train.select('label','features'))\n",
    "\n",
    "    # Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "    # in the earlier example\n",
    "    trainingSummary = lrModel.summary\n",
    "\n",
    "    lrResult=trainingSummary.predictions.select(\"label\",\"prediction\")\n",
    "    \n",
    "    return lrResult\n",
    "\n",
    "def DT():\n",
    "    global dtModel\n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "\n",
    "    # Train a DecisionTree model.\n",
    "    dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "    # Chain indexers and tree in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    dtModel = pipeline.fit(train)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = dtModel.transform(test)\n",
    "\n",
    "    dtResult=predictions.select(\"label\",\"prediction\")\n",
    "    \n",
    "    return dtResult\n",
    "\n",
    "def RF():\n",
    "    global rfModel\n",
    "    \n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "\n",
    "    # Train a RandomForest model.\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "    # Convert indexed labels back to original labels.\n",
    "    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                   labels=labelIndexer.labels)\n",
    "\n",
    "    # Chain indexers and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    rfModel = pipeline.fit(train)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = rfModel.transform(test)\n",
    "\n",
    "    rfResult=predictions.select(\"label\", \"prediction\")\n",
    "    \n",
    "    return rfResult\n",
    "\n",
    "def ANN():\n",
    "    global annModel\n",
    "    \n",
    "    \n",
    "    # specify layers for the neural network:\n",
    "    #Count of features alone in input layer\n",
    "    #No of output classes in output layer\n",
    "\n",
    "    #layers = [3, 6,7, 2]\n",
    "    layers = [17, 18, 2]\n",
    "\n",
    "    # create the trainer and set its parameters\n",
    "    trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "    # train the model\n",
    "    annModel = trainer.fit(train)\n",
    "\n",
    "    # compute accuracy on the test set\n",
    "    result = annModel.transform(test)\n",
    "    annResult = result.select( \"label\",\"prediction\")\n",
    "    return annResult\n",
    "\n",
    "def GBT():\n",
    "    global gbtModel\n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "    # Train a GBT model.\n",
    "    gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "    # Chain indexers and GBT in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    gbtModel = pipeline.fit(train)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = gbtModel.transform(test)\n",
    "\n",
    "    gbtResult=predictions.select(\"label\",\"prediction\")\n",
    "    \n",
    "    return gbtResult\n",
    "\n",
    "def NB():\n",
    "    global nbModel\n",
    "    \n",
    "    # create the trainer and set its parameters\n",
    "    nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "    # train the model\n",
    "    nbModel = nb.fit(train)\n",
    "\n",
    "    # select example rows to display.\n",
    "    predictions = nbModel.transform(test)\n",
    "    nbResult=predictions.select(\"label\",\"prediction\")\n",
    "    \n",
    "    return nbResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7c0487ade0f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bankData.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mparsedData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsePoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqlContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsedData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "data = sc.textFile(\"bankData.csv\")\n",
    "parsedData = data.map(parsePoint)\n",
    "data=sqlContext.createDataFrame(parsedData,['label','features'])\n",
    "\n",
    "(train, test) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "techniqueCount=4\n",
    "\n",
    "#lrCM=LR().rdd.map(confCalc)\n",
    "rfCM=RF().rdd.map(confCalc)\n",
    "annCM=ANN().rdd.map(confCalc)\n",
    "dtCM=DT().rdd.map(confCalc)\n",
    "gbtCM=GBT().rdd.map(confCalc)\n",
    "#nbCM=NB().rdd.map(confCalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metricsDF=[]\n",
    "#metricsDF.append(paramCalc(lrCM))\n",
    "metricsDF.append(paramCalc(rfCM))\n",
    "metricsDF.append(paramCalc(annCM))\n",
    "metricsDF.append(paramCalc(dtCM))\n",
    "metricsDF.append(paramCalc(gbtCM))\n",
    "#metricsDF.append(paramCalc(nbCM))\n",
    "\n",
    "metricResults=[]\n",
    "\n",
    "count=0\n",
    "\n",
    "for results in metricsDF:\n",
    "    tempMetrics=[algos[count]]\n",
    "    a=results.rdd.collect()\n",
    "    for x in a[0]:\n",
    "        tempMetrics.append(x)\n",
    "    \n",
    "    metricResults.append(tempMetrics)\n",
    "    count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RULE BUILDING\n",
    "\n",
    "metrics=sqlContext.createDataFrame(metricResults,[\"Technique\",\"tp\",\"fp\",\"tn\",\"fn\",\"fpr\",\"tpr\",\"tnr\",\"fnr\",\"recall\",\"precision\",\"accuracy\",\"fmeasure\",\"error\"])\n",
    "#Techniques with best TPR (a)\n",
    "\n",
    "trueSelection=metrics.orderBy(metrics.tpr.desc()).limit(1)\n",
    "    \n",
    "#Techniques with best TNR (b)\n",
    "falseSelection=metrics.orderBy(metrics.tnr.desc()).limit(1)\n",
    "    \n",
    "selectedAlgos=falseSelection.union(trueSelection).rdd.collect()\n",
    "#selectedAlgos=selectedAlgos.distinct().orderBy(selectedAlgos.fmeasure).rdd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo Index:0\n",
      "Algo Index:1\n"
     ]
    }
   ],
   "source": [
    "probabilityLevels=[]\n",
    "\n",
    "for trueAlgos in selectedAlgos:\n",
    "    #Contains all predictions\n",
    "    #print trueAlgos\n",
    "    probabilityLevels.append(getModel(trueAlgos['Technique']).select('prediction').rdd.collect())\n",
    "    \n",
    "\n",
    "probabilityList={}\n",
    "for algoIndex,algo in enumerate(probabilityLevels):\n",
    "    print \"Algo Index:\"+str(algoIndex)\n",
    "    for index,pred in enumerate(algo):\n",
    "        if algoIndex==0:\n",
    "            probabilityList[index]=pred['prediction']\n",
    "        else:\n",
    "            if pred['prediction']==1:\n",
    "                probabilityList[index]=1.0\n",
    "\n",
    "\n",
    "labelList=test.select('label').rdd.collect()\n",
    "finalPred=[]\n",
    "for index in probabilityList:\n",
    "    finalPred.append([labelList[index]['label'],probabilityList[index]])\n",
    "    \n",
    "finalDF=sqlContext.createDataFrame(finalPred,['label','prediction'])\n",
    "\n",
    "#Find Confusion Matrix\n",
    "\n",
    "finalResult=finalDF.select('label','prediction').rdd.map(confCalc)\n",
    "\n",
    "#Find Metrics\n",
    "\n",
    "finalMetrics=paramCalc(finalResult)\n",
    "\n",
    "predMetrics=finalMetrics.rdd.collect()[0]\n",
    "\n",
    "finalMetrics=['Proposed']\n",
    "\n",
    "\n",
    "for x in predMetrics:\n",
    "    finalMetrics.append(x)\n",
    "    \n",
    "finalResults=metricResults\n",
    "finalResults.append(finalMetrics)\n",
    "\n",
    "for algo in finalResults:\n",
    "    prof=profitCalc(algo)\n",
    "    algo.append(prof[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technique,tp,fp,tn,fn,fpr,tpr,tnr,fnr,recall,precision,accuracy,fmeasure,error,loss\n",
      "\n",
      "RF,86.0,14.0,100121.0,3737.0,0.000139811254806,0.0224954224431,0.999860188745,0.977504577557,0.0224954224431,0.86,0.96391812078,0.0438439969411,0.0360818792205,375582.5,\n",
      "\n",
      "ANN,623.0,428.0,99707.0,3200.0,0.00427422978978,0.162961025373,0.99572577021,0.837038974627,0.162961025373,0.592768791627,0.965101290906,0.255642183012,0.0348987090941,322028.0,\n",
      "\n",
      "DT,553.0,350.0,99785.0,3270.0,0.00349528137015,0.144650797803,0.99650471863,0.855349202197,0.144650797803,0.612403100775,0.965178245061,0.23402454507,0.0348217549395,328985.0,\n",
      "\n",
      "GBT,826.0,360.0,99775.0,2997.0,0.00359514655215,0.216060685326,0.996404853448,0.783939314674,0.216060685326,0.696458684654,0.967708112892,0.329806348573,0.0322918871083,301558.5,\n",
      "\n",
      "Proposed,842.0,366.0,99769.0,2981.0,0.00365506566136,0.220245880199,0.996344934339,0.779754119801,0.220245880199,0.69701986755,0.967804305585,0.334724706818,0.0321956944151,299956.5,\n"
     ]
    }
   ],
   "source": [
    "f=open('BankResults.csv','w')\n",
    "\n",
    "f.write(\"\\nTechnique,tp,fp,tn,fn,fpr,tpr,tnr,fnr,recall,precision,accuracy,fmeasure,error,loss\")\n",
    "print(\"Technique,tp,fp,tn,fn,fpr,tpr,tnr,fnr,recall,precision,accuracy,fmeasure,error,loss\")\n",
    "\n",
    "for metrics in finalResults:\n",
    "    line=\"\\n\"\n",
    "    for m in metrics:\n",
    "        line+=str(m)+\",\"\n",
    "        \n",
    "    f.write(line)\n",
    "    print(line)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
